title: 实现iPhone X的AniMoji功能
date: 2017-11-23 23:12:15
tags:
- 项目
- Android
- 机器学习
-----
![加载失败,请刷新](/img/poop1.jpg)

> 苹果总是能隔三差五地带给人们惊喜，今年的iPhone X作为iPhone的十周年纪念版，加入了众多黑科技功能，而作为其中之一，即使对 iPhone X 再无感的人，应该都无法拒绝 *Animoji*这个魔性的功能。


![加载失败,请刷新](/img/poop2.png)

>*AniMoji*作为iPhone X的独占功能，目前只能在X这一款机型上体验（甚至连iPhone8都不行），而且目前也只在iMessage里有应用。个人曾经在iPhone X发布很久之前，做过一个类似的APP叫[颜艺Boy](http://www.pengzhihui.xyz/2017/02/22/faceapp/)，也是用来同步用户的表情的。但是当然啦，如果苹果决定要做某一件事情，一定会把它做到极致体验再发布的，所以跟我当时那个APP比起来，AniMoji的效果要好非常多。一方面是由于X搭载了神经网络处理器，所以可以使用复杂得多的网络模型，另一方面苹果的3D动画建模是老牌强项（毕竟乔布斯拥有的另一家公司名字叫做皮克斯:D），仔细看就会发现它并不是使用一个标准的骨架套在每个模型上面，而且针对每个独特的猫啊狗子啊外星人啊进行专门的动画表情建模（比如机器人的嘴，动物的耳朵等，都是可以以特定的方式动的），所以表现出来的动画人物的表情才会非常生动可爱。

![加载失败,请刷新](/img/poop3.jpg)

> 对个人而言，作为对当时颜艺Boy的改进，我重新实现了一套算法，这次主要基于CLM模型。算法步骤还是差不多，首先提取出人脸的一系列关键点，然后进行头部姿态评估，将旋转矩阵映射到3D模型，同时表情的同步也是基于人眼、嘴巴、眉毛等关键点的位置变化。相比于之前的算法，这次的改进最明显的是提取点的稳定性比之前要好很多，也就是说点不会再不停地抖动，这样就给后面的旋转矩阵计算带来 了很大的好处，体现出来的效果就是表情可以做的更加生动了（因为稳定性好就可以把人脸的表情放大而不用担心噪声抖动也被放大，所以夸张的表情会更有卡通效果）。另一个改进就是提高了算法的执行效率，实时性会更好一些。


    看一下效果：
<div style="height: 0;padding-bottom: 61%;position: relative;">
<iframe width="560" height="315" src="http://player.youku.com/embed/XMzE3OTg1NDk1Ng" frameborder="0" allowfullscreen="" style="position: absolute;height: 100%;width: 100%;"></iframe>
</div>  

<br /> 

> 算法基本搞定了，现在正在往Android上移植，网络模型还有点大需要裁剪，单目摄像头的效果跟iPhone X的3D结构光sensor肯定还是有点差距的。后面有机会也研究一下这个来自Kinect团队的黑科技结构光传感器↓

![加载失败,请刷新](/img/poop4.jpg)



> **另，有没得擅长3D角色建模的小伙伴，诚邀帮我出几个图[勾引]，自己胡撸了两天blender感觉建出来的模型跟屎一样:C**

